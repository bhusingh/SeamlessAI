# MindSharedAI

**Unified AI context layer across multiple LLM providers.**

MindSharedAI maintains seamless, persistent user context across ChatGPT, Perplexity, and other LLM providersâ€”synthesizing coherent responses that feel like talking to a single, informed assistant.

## ğŸ¯ Core Idea

Instead of isolated conversations in each LLM:
- Query ChatGPT â†’ get an answer
- Switch to Perplexity â†’ lose context
- Start over

**With MindSharedAI:**
- One unified context across all providers
- Ask ChatGPT, then Perplexity, and they both know your conversation history
- Responses synthesized into one coherent answer

## âœ¨ MVP Features

- âœ… **Multi-provider dispatch** â€” Query OpenAI (GPT-4o) + Perplexity + Claude APIs concurrently
- âœ… **Persistent context** â€” Per-user memory stored in JSON (SQLite/DB coming soon)
- âœ… **Smart aggregation** â€” Combine responses via concatenation or meta-summarization
- âœ… **Adapter pattern** â€” Easy to add more LLM providers
- âœ… **Streamlit UI** â€” Quick testing interface

## ğŸš€ Quick Start

### Prerequisites
- Python 3.9+
- OpenAI API key (get one at https://platform.openai.com/account/api-keys)

### Install & Run

```bash
# Clone repo
git clone https://github.com/bhusingh/mindshared.git
cd mindshared

# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set your OpenAI API key
cp .env.example .env
# Edit .env and add your OpenAI API key
nano .env

# Run the app
streamlit run main.py
```

Open your browser to `http://localhost:8501` ğŸ‰

## ğŸ“– How It Works

### Architecture

```
User Query
    â†“
Context Manager (loads per-user history)
    â†“
Dispatcher (sends to provider APIs concurrently)
    â”œâ”€â†’ OpenAI ChatGPT API
    â”œâ”€â†’ Perplexity API
    â””â”€â†’ Anthropic Claude API
    â†“
Aggregator (synthesizes responses)
    â”œâ”€ Option 1: Concatenate (simple)
    â””â”€ Option 2: Meta-summarize (LLM synthesizes one answer)
    â†“
Response + Context Update
```

### Providers

**OpenAI Provider**
- Model: `gpt-4o` (change to `gpt-5` if available)
- Temperature: 0.2 (factual)

**Perplexity Provider**
- Uses real Perplexity API (when available)
- Fallback to simulated for testing

**Claude Provider**
- Coming in v2.0

### Context Storage

User conversations stored in `user_context.json`:
```json
{
  "user1": [
    "User: What is machine learning?",
    "MindSharedAI: Machine learning is...",
    "User: Tell me about neural networks.",
    "MindSharedAI: Neural networks are..."
  ]
}
```

## ğŸ§ª Testing

1. Enter a **User ID** (e.g., `user1`)
2. Ask a **Query** (e.g., "What is machine learning?")
3. Select **Aggregation mode**:
   - `concatenate`: Simple side-by-side responses
   - `meta-summarize`: LLM synthesizes into one coherent answer
4. Click **Submit** and watch responses stream in

**Test context persistence:**
- Ask a follow-up question (e.g., "Tell me about neural networks based on what we discussed")
- MindSharedAI remembers your first question âœ…

## ğŸ“‚ Project Structure

```
mindshared/
â”œâ”€â”€ main.py                      # Streamlit UI entry point
â”œâ”€â”€ providers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ openai_provider.py       # OpenAI adapter
â”‚   â””â”€â”€ perplexity_provider.py   # Perplexity adapter
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ context_manager.py       # Per-user memory (JSON storage)
â”‚   â”œâ”€â”€ dispatcher.py            # Concurrent multi-provider queries
â”‚   â””â”€â”€ aggregator.py            # Response synthesis
â”œâ”€â”€ requirements.txt             # Dependencies
â”œâ”€â”€ .env.example                 # Environment variables template
â”œâ”€â”€ README.md                    # This file
â””â”€â”€ LICENSE                      # MIT License
```

## ğŸ”§ Configuration

Edit `.env`:

```bash
OPENAI_API_KEY=sk-your-actual-key-here
```

Optional settings in provider files:
- `openai_provider.py`: Change `model="gpt-4o"` to `"gpt-5"` if available
- Add Perplexity API key when integrating real API

## ğŸ›£ï¸ Roadmap

| Version | Status | Timeline | Focus |
|---------|--------|----------|-------|
| **v1.0** | âœ… Complete | Now | Python backend MVP, Streamlit UI, multi-provider dispatch |
| **v1.1** | ğŸ”„ Next | 1-2 weeks | Chrome extension (ChatGPT/Perplexity sidebar integration) |
| **v1.2** | ğŸ“‹ Planned | 2-3 weeks | Deploy backend to cloud (Railway/Render) |
| **v2.0** | ğŸ“‹ Planned | Month 1-2 | Real Perplexity API, Claude full integration |
| **v2.1** | ğŸ“‹ Planned | Month 2 | Vector embeddings, semantic deduplication, smarter context |
| **v3.0** | ğŸ“‹ Later | Q2 2026 | Multi-user SaaS, auth, hosting (if needed) |

### Why this roadmap?

- **v1.1 Chrome extension** is where the real UX magic happensâ€”users won't leave ChatGPT
- **v1.2 Cloud deployment** makes the extension actually useful (no localhost requirement)
- **v2.x improvements** focus on AI quality (better context, real APIs)
- **v3.0 SaaS** only if we want to commercialize (optional)

## ğŸš¨ Known Limitations

- **Perplexity adapter is simulated** â€” Uses OpenAI with different prompts until real API is available
- **JSON storage** â€” Suitable for testing; will migrate to SQLite/PostgreSQL for production
- **No auth** â€” Single-user mode; multi-user coming in v3.0
- **Streamlit UI** â€” Good for testing; real UX will be Chrome extension

## ğŸ¤ Contributing

We'd love contributions! Priority areas:

- âœ… **v1.1:** Chrome extension integration
- âœ… **v1.1:** Real Perplexity API adapter
- âœ… **v2.0:** Claude provider adapter
- âœ… **v2.0:** Gemini provider adapter
- âœ… **v2.1:** Vector embeddings for context
- âœ… **General:** Database backend (SQLite/PostgreSQL)
- âœ… **General:** Better error handling & logging

## ğŸ“œ License

MIT License â€” See [LICENSE](LICENSE) for details.

## ğŸ‘¤ Author

Built by [@bhusingh](https://github.com/bhusingh)

## ğŸ’¬ Questions?

- Open an [issue](https://github.com/bhusingh/mindshared/issues)
- Check [discussions](https://github.com/bhusingh/mindshared/discussions)

---

**Status:** Early MVP in active development. Star â­ to follow progress!